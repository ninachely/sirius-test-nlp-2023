{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from typing import Dict\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelWithLMHead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!python prepare_messages.py --tg-history-path \"data/result.json\" --output-path \"data/data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to /home/consent-flower/.cache/huggingface/datasets/csv/default-fb59fe54b251cb45/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7f72ee1eaf743bfa054b38d9f092fe7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c7899e931d64b97b2616120c85cc20a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "336cf5f0a9bf4dceb2121aee5b5ad8b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/consent-flower/anaconda3/lib/python3.9/site-packages/datasets/download/streaming_download_manager.py:776: FutureWarning: the 'mangle_dupe_cols' keyword is deprecated and will be removed in a future version. Please take steps to stop the use of 'mangle_dupe_cols'\n",
      "  return pd.read_csv(xopen(filepath_or_buffer, \"rb\", use_auth_token=use_auth_token), **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /home/consent-flower/.cache/huggingface/datasets/csv/default-fb59fe54b251cb45/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317. Subsequent calls will reuse this data.\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = \"data/data.csv\"\n",
    "\n",
    "data = load_dataset(\"csv\", data_files=DATA_PATH, split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['context_3', 'context_2', 'context_1', 'response'],\n",
      "    num_rows: 121829\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7a1df72b8e34625b7d6514dca00093e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/121829 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = data.filter(lambda example: example[\"context_1\"] != None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['context_3', 'context_2', 'context_1', 'response'],\n",
      "    num_rows: 79105\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context_3': None,\n",
       " 'context_2': None,\n",
       " 'context_1': 'норм цвет)',\n",
       " 'response': 'Грустно видеть Диану с ником куратора\\nто есть ты больше не наш куратор?(('}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context_3': [None],\n",
       " 'context_2': [None],\n",
       " 'context_1': ['берешь хакатон'],\n",
       " 'response': ['Хакатоны эт другое']}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.train_test_split(test_size=0.2, shuffle=True)\n",
    "data['train'][0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context_3': [None],\n",
       " 'context_2': [None],\n",
       " 'context_1': ['берешь хакатон'],\n",
       " 'response': ['Хакатоны эт другое']}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['train'][0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIRST_SPEAKER_TOKEN = '@@ПЕРВЫЙ@@'\n",
    "SECOND_SPEAKER_TOKEN = '@@ВТОРОЙ@@'\n",
    "\n",
    "CONTEXT_COLS = ['context_3', 'context_2', 'context_1']\n",
    "RESPONSE_COL = ['response']\n",
    "\n",
    "def convert_to_dialog(sample: Dict[str, str]) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "        Convert sample row to dialogs str format\n",
    "    \"\"\"\n",
    "    c1 = sample['context_1'] # already filtered\n",
    "\n",
    "    if 'context2' in sample:\n",
    "        c2 = \"\" if sample['context_2'] is None else sample['context_2']\n",
    "    else:\n",
    "        c2 = \"\"\n",
    "    \n",
    "    if 'context3' in sample:\n",
    "        c3 = \"\" if sample['context_3'] is None else sample['context_3']\n",
    "    else:\n",
    "        c3 = \"\"\n",
    "    \n",
    "    if 'response' in sample:\n",
    "        r = \"\" if sample['response'] is None else sample['response']\n",
    "    else:\n",
    "        r = \"\"\n",
    "\n",
    "    if c2 == \"\" and c3 == \"\":\n",
    "        result = FIRST_SPEAKER_TOKEN + ' ' + c1 + ' ' + SECOND_SPEAKER_TOKEN + ' ' + r\n",
    "    elif c2 == \"\" and c3 != \"\":\n",
    "        result = FIRST_SPEAKER_TOKEN + ' ' + c3 + ' ' + FIRST_SPEAKER_TOKEN + ' ' + c1 + ' ' + SECOND_SPEAKER_TOKEN + ' ' + r\n",
    "    elif c2 != \"\" and c3 == \"\":\n",
    "        result = SECOND_SPEAKER_TOKEN + ' ' + c2 + ' ' + FIRST_SPEAKER_TOKEN + ' ' + c1 + ' ' + SECOND_SPEAKER_TOKEN + ' ' + r\n",
    "    else:\n",
    "        result = FIRST_SPEAKER_TOKEN + ' ' + c3 + ' ' + SECOND_SPEAKER_TOKEN + ' ' + c2 + ' ' + \\\n",
    "              FIRST_SPEAKER_TOKEN + ' ' + c1 + ' ' + SECOND_SPEAKER_TOKEN + ' ' + r\n",
    "    \n",
    "    return {'text': result}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': '@@ПЕРВЫЙ@@ как дела? @@ВТОРОЙ@@ супер)'}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_to_dialog(\n",
    "    {\n",
    "        'context_3': 'привет',\n",
    "        'context_2': 'привет!',\n",
    "        'context_1': 'как дела?',\n",
    "        'response': 'супер)'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': '@@ПЕРВЫЙ@@ как дела? @@ВТОРОЙ@@ супер)'}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_to_dialog(\n",
    "    {\n",
    "        'context_1': 'как дела?',\n",
    "        'response': 'супер)'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1260059/2175699592.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m assert convert_to_dialog(\n\u001b[0m\u001b[1;32m      2\u001b[0m     {\n\u001b[1;32m      3\u001b[0m         \u001b[0;34m'context_3'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'привет'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;34m'context_2'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'привет!'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;34m'context_1'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'как дела?'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert convert_to_dialog(\n",
    "    {\n",
    "        'context_3': 'привет',\n",
    "        'context_2': 'привет!',\n",
    "        'context_1': 'как дела?',\n",
    "        'response': 'супер)'\n",
    "    }\n",
    ") == {'text': '@@ПЕРВЫЙ@@ привет @@ВТОРОЙ@@ привет! @@ПЕРВЫЙ@@ как дела? @@ВТОРОЙ@@ супер)'}\n",
    "\n",
    "assert convert_to_dialog(\n",
    "    {\n",
    "        'context_1': 'как дела?',\n",
    "        'response': 'супер)'\n",
    "    }\n",
    ") == {'text': '@@ПЕРВЫЙ@@ как дела? @@ВТОРОЙ@@ супер)'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('tinkoff-ai/ruDialoGPT-medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
